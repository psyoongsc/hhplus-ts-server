# STEP12. 캐싱 전략 적용 보고서

## 부제: 다중 인스턴스 환경에서 Redis 기반의  캐싱을 통한 성능 개선 보고서

---

## 보고서의 목적

본 보고서는 트래픽이 집중되거나 DB 부하가 높은 조회 API에 대해 Redis 기반의 캐싱 전략을 설계·적용함으로써 조회 성능을 개선하는 것을 목적으로 한다.

---

## 개요

- **배경**: 고빈도 호출되는 API에서 성능 병목이 발생이 예상되며, 이는 DB에 직접 접근하는 구조로 인해 전체 응답 지연을 유발한다.
- **문제**: DB 접근 비용이 높고, 동일 쿼리로 반복 조회되는 패턴이 많음.
- **해결 방향**: Redis 캐시를 통해 조회 결과를 저장하고 재활용함으로써 응답 속도 향상 및 DB 부하 감소 유도.

---

## 개념

### Redis 기반 캐시

- 메모리 기반의 빠른 Key-Value 저장소.
- Expiration 설정을 통해 데이터 유효 기간 제어 가능.
- 다중 인스턴스 간 공유 캐시로 활용 가능.

### 캐싱 패턴

- **Cache-Aside (LookAside)**: 애플리케이션에서 먼저 캐시를 조회하고, 없으면 DB 조회 후 캐시에 저장.
- **Write-Through**: DB에 쓰기와 동시에 캐시에 저장.
- **Read-Through**: 캐시가 DB 조회 로직을 포함하여 자체적으로 데이터를 로드.

---

## Redis 캐싱 전략

### 1. LookAside (Cache-Aside)

- **개념**: 애플리케이션이 먼저 캐시를 조회하고, 존재하지 않으면 DB에서 데이터를 조회 후 캐시에 저장.
- **장점**:
    - 캐시 갱신 시점을 애플리케이션이 명확히 통제 가능.
    - 캐시 부하가 없는 경우 빠른 응답 제공.
- **단점**:
    - 캐시 부재 시 동시성 문제(Cache Stampede) 발생 가능성.
    - 캐시 갱신 로직이 분산되어 중복 구현될 위험.
- **적용 예**:
    - 사용자 프로필, 상품 상세 정보 등 자주 변경되지 않는 데이터.
- **특징 및 특이사항**:
    - **명시적 캐시 제어**: 개발자가 캐시 저장과 삭제를 직접 구현.
    - **유연성 우수**: 데이터 조건에 따라 캐시 저장 여부 조정 가능.
    - **Cache Miss 로직 분산**: 여러 곳에서 동일한 키를 갱신하면 일관성 문제 주의.

### 2. WriteThrough

- **개념**: 애플리케이션이 데이터를 DB에 저장하면서 동시에 캐시에도 같은 값을 저장.
- **장점**:
    - DB와 캐시 간 데이터 일관성 유지 용이.
    - 캐시 부하 없이 항상 최신 데이터 제공 가능.
- **단점**:
    - 쓰기 경로에 캐시 로직이 포함되어 latency 증가.
    - 실패 처리 시 복잡한 롤백 처리 요구.
- **적용 예**:
    - 설정 값, 구성 데이터 등 실시간 갱신이 적고 일관성 요구가 높은 데이터.
- **특징 및 특이사항**:
    - **쓰기 집중형 시스템에 적합**: 읽기보다 쓰기가 많은 데이터는 오히려 비효율.
    - **복잡한 예외 처리** 필요: DB와 캐시 저장이 모두 성공해야 함.
    - **쓰기 지연 문제**: 캐시 저장 실패 시 보정 로직 필수.

### 3. ReadThrough

- **개념**: 캐시 미스 시, 캐시 자체가 정의된 로더를 통해 DB에서 데이터를 가져와 저장 후 응답.
- **장점**:
    - 캐시 관리 로직이 한곳에 집중되어 코드 일관성 향상.
    - 자동 로딩 구조로 중복 코드 최소화.
- **단점**:
    - 외부 로더(예: Redis CacheLoader 등) 설정이 필요하고 복잡도 증가.
    - 로더의 실패 시 fallback 처리 필수.
- **적용 예**:
    - 템플릿 데이터, 공통 설정 등 미리 정의된 구조의 데이터.
- **특징 및 특이사항**:
    - **자동화된 캐시 미스 처리**: 로더가 존재하는 경우 미스 처리 일관적.
    - **캐시 라이브러리 종속성 높음**: Spring Cache, Caffeine 등 미들웨어에 의존.
    - **재사용성과 유지보수성 우수**, 단 초기 설정이 까다로움.

### 4. 캐시 만료 및 제거 정책

- **TTL (Time-To-Live)**:
    - 항목별로 만료 시간을 설정하여, 일정 시간이 지나면 캐시가 자동 삭제됨.
    - 예: 사용자 인증 정보 30분, 상품 데이터 2시간.
- **Eviction 정책**:
    - Redis 기본 정책: LRU (Least Recently Used), LFU, TTL 우선 삭제 등.
    - 메모리 한도 초과 시 오래 사용되지 않은 키부터 제거.
- **특이사항**:
    - 비즈니스 중요도에 따라 세분화된 TTL 전략 필요.
    - **LRU 정책과 TTL 혼합 사용** 시 삭제 우선순위 제어 가능.
    - **예외 상황 대응 필요**: TTL 만료 전에 데이터가 변경되면 캐시 무효화 필요.

---

## 캐싱 로직 적용 계층 선정

### 도메인 vs 레포지토리

| 항목 | 도메인 계층 | 레포지토리 계층 |
| --- | --- | --- |
| **장점** | 비즈니스 맥락에서 캐시 적용 용이 | 데이터 액세스 레벨에서 일관성 유지 |
| **단점** | 중복 캐싱 가능성 | 특정 도메인 로직과 분리 어려움 |
| **추천 케이스** | 조건부 로직이 복잡하거나, 특정 파라미터 조합에 따라 캐시 키가 달라질 때 | 단순 조회/쓰기 로직에 대한 캐싱 |

<aside>
💡

**결론**: 일관된 정책을 위해 가능한 한 **레포지토리 계층**에서 우선 캐싱을 적용하되, 복잡한 비즈니스 조건이 존재하는 경우 도메인 계층에서 별도로 캐싱 책임을 갖는 구조도 병행 사용.

</aside>

---

## 성능 테스트

### 변인 제한

- 도메인 계층에 캐싱 적용
- LookAside 캐싱 적용 (첫 요청은 DB 접근 필요)
- 초당 요청 수: 1000
- 인기 판매 상품 조회 API에 5분 간 스트레스 테스트 진행

### 1. 실험

### 1-1. Non-Cache(위) VS Cache(아래)

![image.png](STEP12%20%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%85%E1%85%A3%E1%86%A8%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%AD%E1%86%BC%20%E1%84%87%E1%85%A9%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%201e6f56acc0e1801ab720cd578fdcb699/image.png)

![image.png](STEP12%20%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%85%E1%85%A3%E1%86%A8%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%AD%E1%86%BC%20%E1%84%87%E1%85%A9%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%201e6f56acc0e1801ab720cd578fdcb699/image%201.png)

### 1-2. 성능 비교

| 항목 | 캐시 미사용 | 캐시 사용 | 비고 |
| --- | --- | --- | --- |
| **평균 응답 시간** | 2.89 ms | 2.71 ms | 차이 미미 |
| **최대 응답 시간** | 190.44 ms | 232.66 ms | 캐시 사용 시 오히려 증가 |
| **중앙값 (Median)** | 0.77 ms | 0.94 ms | 캐시 사용 시 소폭 증가 |
| **최소 응답 시간** | 0.01 ms | 0.03 ms | 거의 동일 |
| **P90** | 5.58 ms | 5.48 ms | 비슷 |
| **P95** | 10.54 ms | 8.87 ms | 캐시 사용 시 더 낮음 |
| **에러율** | 0 | 0 | 동일 |
| **체크 수 (성공 응답 수)** | 20,345 | 23,667 | 캐시 사용 시 더 많음 |

## 📈 성능 해석 및 인사이트

### 1. **캐시 사용에도 불구하고 응답 시간 개선 없음**

- 평균 및 중앙값 응답 시간이 오히려 미세하게 **증가**하거나 거의 동일합니다.
- **최대 응답 시간**이 232ms로 늘어난 점은 주목할 만하며, 캐시 로직 내부에서의 지연 가능성, 캐시 초기 로딩 지연(cold cache) 등이 원인일 수 있습니다.
- Heatmap 상에서도 캐시 사용 구간에서 **빨간색 응답 지연 블럭**이 더 많습니다.

### 2. **초당 1000 요청은 ‘스트레스 테스트’ 기준으로는 낮음**

- 현대적인 웹 서버나 마이크로서비스는 수천~수만 RPS를 견디도록 설계되는 경우가 많습니다.
- **1000 RPS는 부하 테스트보다는 ‘부드러운 성능 확인’ 수준**이며, 실제 병목을 확인하려면 2~5배 이상의 RPS 설정이 필요합니다.

### 3. **로컬 테스트의 한계**

- 로컬 환경에서는 CPU, 메모리, I/O, 네트워크 대역폭 등이 제한되어 있습니다.
- 캐시가 실제로 효과를 발휘하는 서버 환경(예: Redis 캐시, CDN, WAS 수준 캐시)과 달리, **단일 프로세스 캐시**는 오히려 병목이 될 수 있음.
- 또한 로컬에서 캐시를 조회하는 비용이 오히려 I/O 호출보다 클 수 있음 (특히 작은 요청일 경우).

## 🧪 개선 및 제안

1. **부하 증가 테스트 필요**
    
    → 초당 5,000 ~ 10,000 요청 수준으로 점진적으로 올려가며 **TPS 한계, 응답 시간 분포, 에러율**을 확인
    
2. **캐시 위치 및 구조 점검**
    
    → 캐시 적중률, 조회 시간, TTL, 캐시 미스 처리 방식 등을 로깅하여 **실제 성능 영향을 파악**
    
3. **프로덕션 유사 환경에서 재테스트**
    
    → 캐시가 효과적인 환경(CDN, WAS 내부 캐시 등)에서 실행해야 정확한 성능 추정 가능
    

### 2. 초당 요청 수 5000으로 재실험

### 2-1. Non-Cache VS Cache

![image.png](STEP12%20%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%85%E1%85%A3%E1%86%A8%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%AD%E1%86%BC%20%E1%84%87%E1%85%A9%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%201e6f56acc0e1801ab720cd578fdcb699/image%202.png)

![image.png](STEP12%20%E1%84%8F%E1%85%A2%E1%84%89%E1%85%B5%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%85%E1%85%A3%E1%86%A8%20%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%AD%E1%86%BC%20%E1%84%87%E1%85%A9%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%201e6f56acc0e1801ab720cd578fdcb699/image%203.png)

### 2-2. 성능 비교

| 지표 항목 | 비캐시 (non-cache) | 캐시 적용 (cache) | 변화 요약 |
| --- | --- | --- | --- |
| **가상 사용자 수 (VU)** | 평균 ~4.6K, 최대 5K | 동일 (최대 5K) | 동일한 부하 조건 |
| **초당 요청 수 (RPS)** | 평균 4.61K | **4.75K** | **소폭 증가 (서버 여유 향상)** |
| **응답 성공 체크 수** | 45,685 | **78,953** | **약 1.7배 증가** |
| **평균 응답시간** | 78.49 ms | **47.69 ms** | **약 40% 감소** |
| **중앙값 (median)** | 10.21 ms | **2.52 ms** | **~75% 감소** |
| **최소 응답시간** | 0.06 ms | **0.02 ms** | 미세 개선 |
| **최대 응답시간** | 1.76 s | **3.34 s** | **일부 요청에서 악화** |
| **p90 응답시간** | 270.02 ms | **120.78 ms** | **55% 감소** |
| **p95 응답시간** | 363.16 ms | **272.28 ms** | **25% 감소** |

## 📈 상세 분석

### ✅ 성능 향상 요소 (캐싱 도입의 긍정 효과)

1. **전체적인 응답 시간 감소**:
    - 평균 응답 시간: 78ms → **47ms (약 40% 개선)**
    - 중앙값: 10ms → **2.5ms** 로 **대부분 요청이 더 빠르게 처리됨**
    - **p90, p95 지표의 개선**은 특히 중요하며, **상위 10~5% 요청에서 눈에 띄는 성능 향상**을 보여줍니다.
2. **처리량 증가**:
    - 성공한 응답 수가 비캐시 대비 **73% 증가**
    - 이는 동일한 테스트 시간 동안 **더 많은 요청을 성공적으로 처리했음을 의미**함
3. **RPS 유지력 개선**:
    - 평균 RPS가 소폭 상승 → 캐시 도입으로 인해 **백엔드 처리 부담이 줄어들었고, 처리율 증가로 이어짐**

---

### ⚠️ 주의할 점

- **최대 응답 시간 악화 (1.76s → 3.34s)**:
    - 특정 요청에서 예외적으로 큰 지연이 발생함 (e.g., 캐시 미스 or 백엔드 병목)
    - **스파이크 원인 파악 필요** – 아웃라이어로 볼 수도 있지만, 무시하지 않고 분석 필요
- **히트맵 상의 넓은 분산 유지**:
    - 전반적으로 더 많은 요청이 빨라졌지만, 여전히 **일부 요청에서 성능 분산 존재**
    - 캐시 미스 처리, 동적 데이터 요청, 비동기 처리 지연 등이 원인일 수 있음

---

## 🧠 결론 및 추천

### 📌 결론

- **캐싱 전략은 전체 성능에 큰 효과를 주었고**, 평균, 중앙값, 상위 지표 모두 개선되었습니다.
- **처리량이 대폭 증가했고**, 대부분의 요청이 더 빠르게 완료됨으로써 실 사용자 경험도 향상되었을 것으로 보입니다.
- 다만, **최대 지연 시간의 증가와 일부 스파이크는 조사가 필요**합니다.

---

## 최종 결론

Redis 기반의 캐싱 전략은 다중 인스턴스 환경에서도 안정적으로 조회 성능을 개선할 수 있는 강력한 도구다. 특히 Cache-Aside와 Write-Through 패턴의 적절한 병행 활용은 시스템 복잡도를 낮추면서도 높은 일관성과 성능을 제공한다. 향후에는 캐시 갱신 자동화, 멀티 레벨 캐시(Memory + Redis) 도입 등 고도화를 통해 더욱 효율적인 구조로 발전시킬 수 있을 것이다.

---